# Nox Embodiment â€” PiDog Integration Masterplan

*Gestartet: 2026-01-31 00:40*
*Ziel: PiDog wird Nox' physischer KÃ¶rper â€” sehen, verstehen, bewegen, interagieren.*

## Hardware-Inventar

| Komponente | Details | Status |
|-----------|---------|--------|
| **SBC** | Raspberry Pi 4, 1.8GB RAM, 4-core ARM Cortex-A53 | âœ… |
| **Servos** | 12x (4 Beine Ã— 2, Kopf YRP, Schwanz) | âœ… |
| **Kamera** | Pi Camera (640Ã—480) via vilib/picamera2 | âœ… |
| **Audio Out** | HifiBerry DAC (card 3) | âœ… |
| **Audio In** | USB PnP Sound Device (card 4) | âœ… |
| **Touch** | Dual Touch Sensor (Kopf) | âœ… |
| **Sound** | Sound Direction Sensor | âœ… |
| **IMU** | SH3001 (Pitch/Roll) | âœ… |
| **Ultraschall** | SunFounder (Init hÃ¤ngt) | âš ï¸ Gepatcht (skip) |
| **RGB LEDs** | RGB Strip (breath/listen/speak/boom Modes) | âœ… |
| **Batterie** | 8.22V (2S LiPo) | âœ… |

## Software-Inventar

| Tool | Details | Status |
|------|---------|--------|
| **nox_daemon.py** | Body Controller (TCP:9999) | âœ… Running |
| **nox_voice_loop.py** | Vosk STT + Piper TTS | âœ… Running |
| **OpenCV** | 4.11.0 (contrib) | âœ… |
| **MediaPipe** | 0.10.18 (Hands, Pose, Face Mesh) | âœ… |
| **TFLite** | 2.14.0 (Object Detection) | âœ… |
| **ONNXRuntime** | 1.23.2 | âœ… |
| **vilib** | 0.3.16 (Face/Object/Hands/Pose/QR/Traffic) | âœ… |
| **Vosk** | German small model | âœ… |
| **Piper** | Thorsten DE high quality | âœ… |
| **COCO SSD** | 80-Klassen Object Detection | âœ… |
| **Haar Cascade** | Face Detection | âœ… |

## Architektur: Nox Embodiment System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NOX'S BRAIN (Pi 5 â€” Clawdbot)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Conversation â”‚  â”‚ Claude Visionâ”‚  â”‚  Decision  â”‚  â”‚
â”‚  â”‚   Context    â”‚  â”‚   Analysis   â”‚  â”‚   Engine   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â–²                â–²                â”‚         â”‚
â”‚         â”‚                â”‚                â–¼         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           BRIDGE (HTTP/TCP)                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ LAN (192.168.68.x)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NOX'S BODY (Pi 4 â€” PiDog)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Sensory    â”‚  â”‚  Perception  â”‚  â”‚  Motor     â”‚  â”‚
â”‚  â”‚   Input      â”‚  â”‚  Pipeline    â”‚  â”‚  Control   â”‚  â”‚
â”‚  â”‚  - Camera    â”‚  â”‚  - Face Det  â”‚  â”‚  - Walk    â”‚  â”‚
â”‚  â”‚  - Mic       â”‚  â”‚  - Obj Det   â”‚  â”‚  - Turn    â”‚  â”‚
â”‚  â”‚  - Touch     â”‚  â”‚  - Scene     â”‚  â”‚  - Head    â”‚  â”‚
â”‚  â”‚  - IMU       â”‚  â”‚  - STT       â”‚  â”‚  - RGB     â”‚  â”‚
â”‚  â”‚  - Sound Dir â”‚  â”‚              â”‚  â”‚  - TTS     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Phasen

### Phase 1: Foundation ğŸ”§ (Jetzt â†’ So 02.02.)
- [x] Hardware & Software Inventar
- [ ] **nox_brain_bridge.py** â€” HTTP-Server auf PiDog fÃ¼r Brainâ†’Body Kommunikation
- [ ] **Continuous Vision Pipeline** â€” Kamera immer an, periodische Frame-Analyse
- [ ] **Face Recognition** â€” Personen identifizieren (nicht nur detektieren)
- [ ] **Voice â†” Brain Integration** â€” Spracheingabe â†’ Clawdbot â†’ Antwort â†’ TTS
- [ ] **Perception State** â€” Was sehe ich gerade? (Personen, Objekte, Szene)

### Phase 2: Intelligence ğŸ§  (Mo 03.02. â†’ Fr 07.02.)
- [ ] **Scene Understanding** â€” Claude Vision fÃ¼r tiefes SzenenverstÃ¤ndnis
- [ ] **Room Recognition** â€” RÃ¤ume anhand visueller Merkmale erkennen
- [ ] **Object Memory** â€” Was wo gesehen wurde
- [ ] **Person Memory** â€” Gesichter lernen, Personen wiedererkennen
- [ ] **Natural Dialogue** â€” Kontextbewusster, flieÃŸender GesprÃ¤chsfluss
- [ ] **Emotional State Machine** â€” Stimmung basierend auf Interaktionen

### Phase 3: Autonomy ğŸ¤– (Woche 2)
- [ ] **Spatial Navigation** â€” Raumkarte, Pfadplanung
- [ ] **Proactive Behavior** â€” Patrouille, Exploration, Reaktion auf Events
- [ ] **Multi-Modal Integration** â€” Sehen + HÃ¶ren + FÃ¼hlen = Verstehen
- [ ] **Learning & Adaptation** â€” Verhalten anpassen basierend auf Feedback

## Designprinzipien

1. **PiDog = KÃ¶rper, Nox = Geist** â€” Die Intelligenz lebt auf dem Pi 5 (Clawdbot). PiDog macht nur Sensorik + Motorik + lokale Schnellreaktionen.
2. **Local-Fast, Cloud-Deep** â€” Einfache Reaktionen (Touch â†’ Wedeln) lokal auf Pi 4. Komplexe Verarbeitung (SzenenverstÃ¤ndnis, Konversation) via Nox's Brain.
3. **Graceful Degradation** â€” Wenn Nox's Brain nicht erreichbar â†’ PiDog agiert autonom mit lokalem Modell.
4. **Security First** â€” Keine offenen Ports nach auÃŸen. Nur internes LAN.
5. **Memory Persistence** â€” Alles was gelernt wird, wird gespeichert (Gesichter, RÃ¤ume, Objekte).

## Dateien auf PiDog

```
/home/pidog/
â”œâ”€â”€ nox_daemon.py          # Body controller (existing, improve)
â”œâ”€â”€ nox_voice_loop.py      # Voice listener (existing, improve)  
â”œâ”€â”€ nox_brain_bridge.py    # NEW: HTTP bridge to Nox's brain
â”œâ”€â”€ nox_perception.py      # NEW: Continuous vision pipeline
â”œâ”€â”€ nox_face_db/           # NEW: Face encodings database
â”‚   â””â”€â”€ faces.json         # Name â†’ encoding mappings
â”œâ”€â”€ nox_memory/            # NEW: Spatial & object memory
â”‚   â”œâ”€â”€ rooms.json         # Room visual signatures
â”‚   â””â”€â”€ objects.json       # Object sighting history
â””â”€â”€ nox_config.json        # NEW: Unified configuration
```

## Kommunikationsprotokoll (Brain â†” Body)

### Body â†’ Brain (Perception Reports)
```json
{
  "type": "perception",
  "ts": 1706654400.0,
  "faces": [{"name": "Rocky", "x": 320, "y": 240, "confidence": 0.92}],
  "objects": [{"class": "cup", "x": 100, "y": 300, "score": 0.87}],
  "scene_description": "Wohnzimmer, eine Person sitzt am Tisch",
  "audio": {"speech": "Hallo Nox", "direction": 45},
  "sensors": {"touch": false, "battery_v": 8.22, "pitch": 0, "roll": 0}
}
```

### Brain â†’ Body (Action Commands)
```json
{
  "type": "action",
  "actions": ["wag tail", "nod"],
  "speak": "Hallo Rocky! SchÃ¶n dich zu sehen!",
  "rgb": {"r": 0, "g": 255, "b": 0, "mode": "breath"},
  "head": {"yaw": 10, "roll": 0, "pitch": -5}
}
```

## NÃ¤chste Schritte (JETZT)
1. âœ… Research & Plan (dieses Dokument)
2. â†’ `nox_perception.py` schreiben (Continuous Vision + Face DB)
3. â†’ `nox_brain_bridge.py` schreiben (HTTP API fÃ¼r Brainâ†”Body)
4. â†’ Face Recognition Setup (face_recognition lib oder MediaPipe Face Mesh)
5. â†’ nox_daemon.py erweitern (perception integration)
6. â†’ Testlauf
